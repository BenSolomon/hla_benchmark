---
title: "Mapping coverage analysis"
output: 
  html_notebook:
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: hide
---
# Setup

```{r}
library(tidyverse)
```

```{r}
source("data_import_functions.R")
hla_fasta <- Biostrings::readDNAStringSet("/labs/khatrilab/solomonb/references/IMGTHLA/hla_nuc.fasta")
```

```{r}
get_hla_id_key <- function(hla_nuc_path = "/labs/khatrilab/solomonb/references/IMGTHLA/hla_nuc.fasta"){
  hla_fasta <- Biostrings::readDNAStringSet(hla_nuc_path)
  tibble(header = names(hla_fasta)) %>% 
  separate(header, into = c("id", "allele", "length"), sep = " ", extra = "drop", remove = F) %>% 
  separate(allele, into = c("locus"), sep = "\\*", extra = "drop", remove = F) %>% 
  select(id, locus)
}

# get_hla_id_key()
```

```{r}
get_kallisto_coverage_stats <- function(alignment_path) {
  hla_id_key <- get_hla_id_key()
  
  samples <- list.dirs(alignment_path, recursive = F) %>% basename()
  tibble(samples = samples) %>%
    mutate(data = map(samples, function(x) {
      path <- sprintf("%s/%s/%s_coverage.txt", alignment_path, x, x)
      tryCatch(
        suppressMessages(read_tsv(
          path,
          col_names = c("id", "position", "coverage"),
          col_types = c("c", "d", "d")
        )),
        error = function(c)
          NA
      )
    })) %>%
    drop_na() %>%
    unnest(data) %>% 
    dplyr::select(!contains("data")) %>% 
    left_join(hla_id_key, by = "id")
}

# get_kallisto_coverage_stats("/labs/khatrilab/solomonb/covid/isb/kallisto/alignment")
```


# Kallisto alignment

### Method

- Use extracted Ch6 and unampped reads from arcasHLA in fastq format
- Create custom `kallisto` index composed of HLA alleles for given sample
- Align fasta with custom index, producing pseudobam file
- Sort
- Extract depth data

### Make sample-specific HLA references

`make_references.R`

```{r, eval = F}
library(tidyverse, quietly = T)
library(Biostrings, quietly = T)
source("/labs/khatrilab/solomonb/hla_project/hla_benchmark/data_import_functions.R")
.libPaths(c("/home/solomonb/R/el7/library/4.0", "/share/sw/R/site-library/4.0", "/opt/R/4.0.4/lib/R/library"))

sample_arg <- commandArgs(trailingOnly = TRUE)[1]
sample_base <- gsub("-.*","", sample_arg)
hla_fasta <- Biostrings::readDNAStringSet("/labs/khatrilab/solomonb/references/IMGTHLA/hla_nuc.fasta")


genotypes_df <- suppressMessages({
  invitro_import(path = "/labs/khatrilab/solomonb/hla_project/hla_benchmark/hla_2020-10-23_1457.tsv") %>% 
  filter(sample == sample_arg) %>% 
  select(sample, allele) %>% 
  distinct()
})

best_allele <- function(pattern, hla_fasta){
  # Finds best HLA ID match given allele ID of any resolution
  # pattern = hla allele of any resolution(e.g. A*01:01:01)
  # hla_fasta = DNAStringSet with all HLA reference sequences
  pattern_locus <- gsub("\\*.*", "", pattern)
  pattern <- sprintf("^%s", Hmisc::escapeRegex(pattern))
  
  tibble(header = names(hla_fasta)) %>% 
    separate(header, into = c("id", "allele", "length"), sep = " ", extra = "drop", remove = F, convert = T) %>% 
    separate(allele, into = c("locus"), sep = "\\*", extra = "drop", remove = F) %>% 
    # Search for all compatible HLA IDs given allele (i.e. multiple 4-field matches may exist if a 3-field pattern is given)
    filter(locus == pattern_locus) %>% 
    filter(grepl(pattern, allele)) %>% 
    # Exclude expression variant allele designations
    filter(!grepl("[A-Z]$", allele)) %>% 
    group_by(locus) %>% 
    # Select longest reference sequence of possible hits (to exclude reference sequences with incomplete exons)
    slice_max(length, with_ties = F) %>% 
    pull(header)
}

hla_ids <- genotypes_df %>% 
  mutate(hla_id = map_chr(allele, function(x){
    best_allele(pattern = x, hla_fasta = hla_fasta)
  })) %>% 
  pull(hla_id)

# hla_fasta[hla_ids]

writeXStringSet(hla_fasta[hla_ids], 
                sprintf("/labs/khatrilab/solomonb/covid/isb/kallisto/references/%s_reference.fasta", sample_base))
```

`make_references.sh`

```{bash, eval = F}
module load R/4.0.4
export SAMPLE_LIST=/labs/khatrilab/solomonb/covid/isb/kallisto/genotyped_samples.tsv
export R_SCRIPT=/labs/khatrilab/solomonb/covid/isb/kallisto/make_references.R

MAKE_REFERENCES(){
  Rscript $R_SCRIPT $1
}

export -f MAKE_REFERENCES

cat $SAMPLE_LIST | parallel --delay 15 -j $SLURM_NTASKS --joblog make_references_parallel.log MAKE_REFERENCES {}
```

### Run alignment

`isb_kallisto_alignment.sh`

```{bash, eval=F}
export BASE_DIR=/labs/khatrilab/solomonb/covid/isb
export INDEX_DIR=$BASE_DIR/kallisto/index
export REF_DIR=$BASE_DIR/kallisto/references
export FASTQ_DIR=$BASE_DIR/arcasHLA
export N_CORES=$SLURM_CPUS_PER_TASK

if [ ! -d $INDEX_DIR ]; then mkdir -p $INDEX_DIR;fi

KALLISTO(){
  source /labs/khatrilab/solomonb/miniconda3/etc/profile.d/conda.sh
  conda activate samtools
  
  OUT_DIR=$BASE_DIR/kallisto/alignment/${1}
  if [ ! -d $OUT_DIR ]; then mkdir -p $OUT_DIR;fi
  
  REFERENCE_NAME=$(echo $1 | awk 'BEGIN {FS="-"};{print $1}')
  
  kallisto index \
  -i $INDEX_DIR/${1}.idx \
  $REF_DIR/${REFERENCE_NAME}_reference.fasta \
  2> $OUT_DIR/${1}.log
  
  kallisto quant \
  -i $INDEX_DIR/${1}.idx \
  -o $OUT_DIR \
  --pseudobam \
  -t $N_CORES \
  --single -l 91 -s 1 \
  $FASTQ_DIR/${1}.extracted.fq.gz \
  2>> $OUT_DIR/${1}.log

  samtools sort \
  -@ $N_CORES \
  -O BAM \
  $OUT_DIR/pseudoalignments.bam \
  > $OUT_DIR/pseudoalignments_sort.bam 2>> $OUT_DIR/${1}.log

  samtools depth \
  -d 0 \
  $OUT_DIR/pseudoalignments_sort.bam \
  > $OUT_DIR/${1}_coverage.txt 2>> $OUT_DIR/${1}.log
  
  rm -r $OUT_DIR/pseudoalignments.bam
}
export -f KALLISTO

cat $BASE_DIR/kallisto/AC_BL_samples.txt | parallel --delay 15 -j $SLURM_NTASKS --joblog kallisto_alignment.log KALLISTO {}
```

- Scripts for pmid data similar, though note `kallisto quant` step must be modified for paired-end data with bulk RNA-seq samples

```{bash, eval=F}
  kallisto quant \
  -i $INDEX_DIR/${1}.idx \
  -o $OUT_DIR \
  --pseudobam \
  -t $N_CORES \
  $FASTQ_DIR/${1}.extracted.1.fq.gz \
  $FASTQ_DIR/${1}.extracted.2.fq.gz \
  2>> $OUT_DIR/${1}.log
```


### Import coverage data


```{r}
isb_coverage_df <- get_kallisto_coverage_stats("/labs/khatrilab/solomonb/covid/isb/kallisto/alignment")
```

```{r}
pmid_3p_coverage_df <- get_kallisto_coverage_stats("/labs/khatrilab/solomonb/covid/pmid30518681/scRNA/kallisto/alignment")
```

```{r}
pmid_bulk_coverage_df <- get_kallisto_coverage_stats("/labs/khatrilab/solomonb/covid/pmid30518681/bulkRNA/kallisto/alignment")
```

```{r}
# coverage_df <- bind_rows(
#   isb_coverage_df %>% mutate(platform = "5p"),
#   pmid_3p_coverage_df %>% mutate(platform = "3p"),
#   pmid_bulk_coverage_df %>% mutate(platform = "bulk")
# ) 
# 
# saveRDS(coverage_df, "kallisto_coverage.RDS")
# coverage_df <- readRDS("kallisto_coverage.RDS")
```


### Plots

#### Coverage segments

```{r, fig.width=18, fig.height = 8}
segment_length <- 50

all_coverage_segment <- coverage_df %>% 
  group_by(samples, locus, id, platform) %>%
  mutate(segment = floor(position/segment_length)*segment_length + 1) %>%
  group_by(samples, locus, id, platform, segment) %>%
  summarise(coverage = mean(coverage)) %>% 
  ungroup()

framework <- all_coverage_segment %>%
  count(samples, locus, id, platform) %>%
  select(-n) %>%
  right_join(all_coverage_segment  %>%
               count(locus, segment) %>%
               select(-n),
             by = c("locus"))

all_coverage_plt <- all_coverage_segment %>%
  right_join(framework, by = names(framework)) %>% 
  filter(locus %in% c("A", "B", "C", "DQA1", "DPB1", "DRB1")) %>%
  mutate(coverage = ifelse(is.na(coverage), 0, coverage)) %>% 
  drop_na() %>% 
  arrange(segment) %>% 
  ggplot(aes(x = segment, y = coverage))+
  geom_path(aes(group = interaction(samples, id)), size = 0.2, alpha = 0.5, color = "grey50")+
  geom_smooth(se = T)+
  facet_grid(platform~locus, scales = "free_x") +
  scale_y_log10() +
  theme_bw() +
  labs(x = "Position (bp)", y = "Coverage")
all_coverage_plt

all_coverage_segment %>%
  right_join(framework, by = names(framework)) %>% 
  filter(locus %in% c("A", "B", "C", "DQA1", "DPB1", "DRB1")) %>%
  mutate(coverage = ifelse(is.na(coverage), 0, coverage)) %>% 
  drop_na() %>% 
  arrange(segment) %>% 
  ggplot(aes(x = segment, y = coverage))+
  geom_jitter(size = 0.01, height = 0, alpha = 0.5, color = "grey50")+
  geom_smooth(se = T)+
  facet_grid(platform~locus, scales = "free_x") +
  scale_y_log10() +
  theme_bw() +
  labs(x = "Position (bp)", y = "Coverage")

```

#### Coverage by bp

```{r, fig.width=18, fig.height = 8}
all_coverage_plt <- coverage_df %>% 
  filter(locus %in% c("A", "B", "C", "DQA1", "DPB1", "DRB1")) %>% 
  ggplot(aes(x = position, y = coverage))+
  geom_point(size = 0.01, alpha = 0.1, color = "grey50")+
  geom_smooth(se = T)+
  facet_grid(platform~locus, scales = "free_x") +
  scale_y_log10() +
  theme_bw()
all_coverage_plt
```
# Sequence diversity data

```{r}
hla_entropy <- readRDS("/labs/khatrilab/solomonb/hla_project/hla_benchmark/hla_sequence_entropy_includeIncomplete.RDS")
```

```{r}
gg_combo_entropy <- function(df, grouping_var){
  grouping_var <- enquo(grouping_var)
  df <- df %>% 
    mutate(grouping = !!grouping_var) %>% 
    group_by(grouping) %>% 
    nest() %>% 
    mutate(layer = map(data, function(x) list(
      geom_path(data = x, stat = "identity", size = 2, aes(group = locus), color = "black"),
      geom_path(data = x, stat = "identity", size = 1.5)
  )))
  ggplot(df, aes(x = position, y = shannon_roll, color = locus)) + 
    df$layer +
    theme_bw()+
    scale_color_brewer(palette = "Set2") +
    labs(y = "Shannon entropy", color = "Loci") 
}
```

```{r, fig.width=18, fig.height = 3}
step <- 100
entropy_plt <- hla_entropy %>% 
  filter(loci %in% c("A", "B", "C", "DQA1", "DPB1", "DRB1")) %>% 
  # filter(grepl("^[ABC]|D[PRQ]B1", loci)) %>% 
  select(locus = loci, entropy) %>% 
  unnest(entropy) %>% 
  group_by(locus) %>% 
  mutate(shannon_roll = zoo::rollapply(shannon, width = step, mean, partial = T)) %>% 
  arrange(position) %>% 
  gg_combo_entropy(., locus) +
  facet_grid(. ~ locus, scale = "free_x") +
  theme(legend.position = "none") +
  labs(x="Position (bp)")
entropy_plt
```
# Mapping efficiency

```{r}
parse_hisat_log <- function(path){
  # For single end reads only
  suppressMessages(
  read_tsv(path, col_names = "reads") %>% 
    mutate(reads = gsub(" .*", "", reads)) %>%
    mutate(reads = str_extract(reads, "[0-9\\.]*")) %>%
    mutate(statistic = c("reads", "unpaired_reads", "unaligned_reads", "single-aligned_reads", "multi-aligned_reads", "alignment_rate")) %>% 
    pivot_wider(names_from = "statistic", values_from = "reads") %>% 
    mutate_all(as.numeric) %>% 
    mutate(alignment_rate = alignment_rate/100) %>% 
    mutate(aligned_reads = reads - unaligned_reads) %>% 
    rename_all(~(sprintf("total_%s",.)))
  )
}

hisat_total_reads <- function(path) {
  suppressMessages(
    read_tsv(path, col_names = "reads") %>%
      dplyr::slice(1) %>%
      mutate(reads = gsub(" .*", "", reads)) %>%
      mutate(reads = str_extract(reads, "[0-9\\.]*")) %>% 
      pull(reads) %>% 
      as.numeric()
  )
}
path <- "/labs/khatrilab/solomonb/covid/isb/logs/210217_232725/INCOV003-BL/INCOV003-BL_hisat.log"
parse_hisat_log(path)
hisat_total_reads(path)
```

```{r}
arcas_log_dir <- sprintf("%s/arcasHLA", isb_path)
log_path <- sprintf("%s/%s.genotype.log",arcas_log_dir,"INCOV003-BL")
log_path
parse_arcas_log <- function(path) {
  df <- tibble(lines = read_lines(path))
  df <- if (any(grepl("error", df$lines, ignore.case = T))) {
    NA
  } else {
    total_reads <- df %>%
      mutate(lines = gsub("\t", "", lines)) %>%
      filter(grepl("^\\[alignment\\] Processed", lines)) %>%
      mutate(lines = gsub("\\,.*", "", lines)) %>%
      mutate(lines = str_extract(lines, "[0-9]+")) %>%
      pull(lines) %>%
      as.numeric()
    df %>%
      mutate(lines = gsub("\t", "", lines)) %>%
      filter(grepl("^HLA", lines)) %>%
      separate(
        lines,
        into = c("locus", "abundance", "locus_reads", "classes"),
        sep = " +"
      ) %>%
      mutate(locus = gsub("HLA\\-","",locus)) %>% 
      mutate_at(vars(!c("abundance", "locus")), as.numeric) %>% 
      mutate(extracted_reads = total_reads) %>% 
      mutate(total_hla_reads = sum((locus_reads)))
  }
  df
}
parse_arcas_log(log_path)
```

```{r}
mapping_efficiency_stats <- function(samples, hisat_dir, arcas_dir) {
  tibble(sample = samples) %>%
    # head() %>%
    mutate(total_reads = map_dbl(sample, function(x) {
      path <- sprintf("%s/%s/%s_hisat.log", hisat_dir, x, x)
      hisat_total_reads(path)
    })) %>%
    mutate(arcas = map(sample, function(x) {
      path <- sprintf("%s/%s.genotype.log", arcas_dir, x)
      parse_arcas_log(path) %>%
        dplyr::select(locus, locus_reads, extracted_reads, total_hla_reads)
    })) %>%
    unnest(arcas) %>%
    mutate(
      total_efficiency = locus_reads / total_reads,
      extracted_efficiency = locus_reads / extracted_reads,
      hla_efficiency = locus_reads / total_hla_reads
    )
}
```

```{r}
p5_samples <- read_tsv("/labs/khatrilab/solomonb/covid/isb/logs/210217_232725/parallel.log") %>% 
  separate(Command, into = c(NA, "sample"), sep = " ") %>%
  filter(grepl("-(AC|BL)$", sample)) %>% 
  pull(sample) %>% unique()
p5_hisat_dir <- "/labs/khatrilab/solomonb/covid/isb/logs/210217_232725"
p5_arcas_dir <- "/labs/khatrilab/solomonb/covid/isb/arcasHLA"

p5_df <- mapping_efficiency_stats(
  samples = p5_samples,
  hisat_dir = p5_hisat_dir,
  arcas_dir = p5_arcas_dir
)

p3_path <- "/labs/khatrilab/solomonb/covid/pmid30518681/scRNA"
p3_samples <- read_tsv(sprintf("%s/sc_sra_accession.txt", p3_path), col_names = "sample") %>% pull(sample)
p3_arcas_dir <- sprintf("%s/arcasHLA", p3_path)
p3_hisat_dir <- sprintf("%s/logs/compiled_hisat_logs", p3_path)

p3_df <- mapping_efficiency_stats(
  samples = p3_samples,
  hisat_dir = p3_hisat_dir,
  arcas_dir = p3_arcas_dir
)

bulk_path <- "/labs/khatrilab/solomonb/covid/pmid30518681/bulkRNA"
bulk_samples <- read_tsv(sprintf("%s/bulk_sra_accession.txt", bulk_path), col_names = "sample") %>% pull(sample)
bulk_arcas_dir <- sprintf("%s/arcasHLA", bulk_path)
bulk_hisat_dir <- sprintf("%s/logs/compiled_hisat_logs", bulk_path)

bulk_df <- mapping_efficiency_stats(
  samples = bulk_samples,
  hisat_dir = bulk_hisat_dir,
  arcas_dir = bulk_arcas_dir
)
```
```{r}
bind_rows(
  p5_df %>% mutate(platform = "p5"),
  p3_df %>% mutate(platform = "p3"),
  bulk_df %>% mutate(platform = "bulk")
) %>% 
  filter(grepl("^[ABC]|^D[PQR][AB]1", locus)) %>% 
  dplyr::select(sample, locus, platform, contains("efficiency")) %>% 
  pivot_longer(contains("efficiency"), names_to = "class", values_to = "efficiency") %>% 
  # filter(class != "hla_efficiency") %>% 
  ggplot(aes(x = locus, y = efficiency, fill = platform)) +
  stat_summary(
    fun = mean,
    position = "dodge",
    geom = "bar",
    color = "black"
  ) +
  stat_summary(
    fun.data = mean_se,
    position = position_dodge(width = 0.9),
    geom = "errorbar",
    width = 0.5
  ) +
  facet_wrap(~class, nrow = 1, scales = "free_y") +
  theme_bw() +
    scale_fill_grey(start = 1, end = 0.25) +
   scale_y_sqrt() 
```
```{r}
efficiency_plt <- bind_rows(
  p5_df %>% mutate(platform = "p5"),
  p3_df %>% mutate(platform = "p3"),
  bulk_df %>% mutate(platform = "bulk")
) %>%
  filter(grepl("^[ABC]|^D[PQR][AB]1", locus)) %>%
  dplyr::select(sample, locus, platform, contains("efficiency")) %>%
  pivot_longer(contains("efficiency"),
               names_to = "class",
               values_to = "efficiency") %>%
  filter(class == "total_efficiency") %>%
  filter(locus %in% c("A", "B", "C", "DQA1", "DPB1", "DRB1")) %>% 
  ggplot(aes(x = platform, y = efficiency*1000000)) +
  geom_violin(scale = "width", fill = "grey85")+
  geom_boxplot(width = 0.1, size = 0.2,outlier.shape = NA)+
  facet_grid(. ~ locus, scales = "free_x") +
  theme_bw() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_fill_grey(start = 1, end = 0.75) +
  # scale_y_sqrt() +
  scale_y_log10()+
  labs(y = "Mapped reads\n(per million reads)", x = "")
efficiency_plt
```

# Assembled plots

```{r}
match_x_axis <- function(target, source) {
  # Convert source to ggplot_build
  source <- ggplot_build(source)
  # Get the name of the facet column variable
  col_var <- names(source$layout$facet_params$cols)
  # Get the names of the facet column elements
  source_data <- source$layout$layout
  col_options <- source_data[source_data$ROW == 1, col_var]
  # Get limits of all facets
  limit_list <- lapply(source$layout$panel_scales_x,
                     function(z)
                       z$range$range)
  # Name each element in list
  names(limit_list) <- col_options
  # Convert list to forumula
  form_list <- enframe(limit_list) %>%
    mutate(data = map2(name, value, function(x, y) {
      form <-
        sprintf("%s == '%s' ~ scale_x_continuous(limits = c(%s))",
                col_var,
                x,
                toString(y))
      as.formula(form)
    })) %>% 
    pull(data)
  
  # Apply to target
  target + ggh4x::facetted_pos_scales(x = form_list)
}
```


```{r, fig.width=10, fig.height = 8}
cowplot::plot_grid(
  match_x_axis(target = entropy_plt, source = all_coverage_plt)+labs(x="Position (bp)"),
  all_coverage_plt,
  efficiency_plt,
  ncol = 1,
  rel_heights = c(2,5,2),
  align = "v",
  axis = "lr"
)
```



